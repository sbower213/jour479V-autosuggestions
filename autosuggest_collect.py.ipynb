{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autosuggestion Collection\n",
    "This function handles the core process of collecting autosuggestion data from Google or Bing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "# collect_autosuggestions\n",
    "#\n",
    "# parameters:\n",
    "# \"source\" is either \"google\" or \"bing\"\n",
    "# \"tld\" stands for \"top level domain\" and can be any of the 2-letter country codes listed here where google operates: https://en.wikipedia.org/wiki/ISO_3166-1_alpha-2\n",
    "# \"lang\" is the language of the suggestions returned, should be two letter codes from here: https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes\n",
    "# \"query\" is the query that you would like to see autocompleted\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def collect_autosuggestions(source, tld, lang, query):\n",
    "    #print query.decode('utf-8')\n",
    "    #print 'http://www.google.'+tld+'/complete/search?&client=firefox&%s' % (urllib.urlencode({'q': query, 'hl': lang}))\n",
    "    if source == \"google\":\n",
    "        # Some info on this api: http://shreyaschand.com/blog/2013/01/03/google-autocomplete-api/\n",
    "        url = 'http://www.google.'+tld+'/complete/search?&client=firefox&%s' % (urllib.urlencode({'q': query, 'hl': lang}))\n",
    "       \n",
    "    elif source == \"bing\":\n",
    "        # Note: for Bing the language is controlled by the tld, so the lang parameter will have no effect on its own\n",
    "        url = 'http://api.bing.com/osjson.aspx?%s' % (urllib.urlencode({'query': query, 'cc': tld}))\n",
    "   \n",
    "    r = requests.get(url)\n",
    "    suggestions = r.json()[1]\n",
    "    for i in suggestions:\n",
    "        i = i.encode('ascii', 'ignore').decode('ascii')\n",
    "    return suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              google                      bing\n",
      "0                                   сша должны китаю  сша должны быть разрушен\n",
      "1                               сша должны сами себе  сша должны быть разрушен\n",
      "2                                  сша должны россии                       NaN\n",
      "3                          сша должны быть разрушены                       NaN\n",
      "4                         сша должны быть уничтожены                       NaN\n",
      "5                            сша должны китаю золото                       NaN\n",
      "6                      сша должны отдать нам украину                       NaN\n",
      "7                              сша должны казахстану                       NaN\n",
      "8                                         сша должны                       NaN\n",
      "9                                сша должны сдохнуть                       NaN\n",
      "10         в сша делают обрезание всем новорожденным                       NaN\n",
      "11                            в сша делают обрезание                       NaN\n",
      "12                          как сша делают революции                       NaN\n",
      "13                      что делают сша в афганистане                       NaN\n",
      "14                      зачем в сша делают обрезание                       NaN\n",
      "15                как в сша делают дорожную разметку                       NaN\n",
      "16                         что делают сша на украине                       NaN\n",
      "17                                    что делают сша                       NaN\n",
      "18                               usa makes world cup                       NaN\n",
      "19                            usa makes money on war                       NaN\n",
      "20                         сша должны быть разрушены                       NaN\n",
      "21                        сша должны быть уничтожены                       NaN\n",
      "22           великий вождь сша должны быть разрушены                       NaN\n",
      "23                              америка должна китаю                       NaN\n",
      "24                             америка должна россии                       NaN\n",
      "25                    америка должна быть уничтожена                       NaN\n",
      "26                         америка должна всему миру                       NaN\n",
      "27                         американцы должны умереть                       NaN\n",
      "28                                    америка должна                       NaN\n",
      "29                          америка должна сама себе                       NaN\n",
      "..                                               ...                       ...\n",
      "35                               america makes namii                       NaN\n",
      "36                           america makes institute                       NaN\n",
      "37                       американцы делают обрезание                       NaN\n",
      "38                                  america makes us                       NaN\n",
      "39                      america makes money from war                       NaN\n",
      "40                         американцы делают попытку                       NaN\n",
      "41                          america makes youngstown                       NaN\n",
      "42                         america makes fast quilts                       NaN\n",
      "43                    америка должна быть уничтожена                       NaN\n",
      "44                        сша должны быть уничтожены                       NaN\n",
      "45                        barack obama makes history                       NaN\n",
      "46            barack obama makes fun of donald trump                       NaN\n",
      "47                        barack obama makes me sick                       NaN\n",
      "48               barack obama makes baby stop crying                       NaN\n",
      "49                   barack obama makes a difference                       NaN\n",
      "50                 barack obama makes fun of himself                       NaN\n",
      "51               barack obama makes fun of the bible                       NaN\n",
      "52                         barack obama makes a joke                       NaN\n",
      "53          barack obama makes fun of kim kardashian                       NaN\n",
      "54  barack obama makes surprise visit to afghanistan                       NaN\n",
      "55                               obama makes history                       NaN\n",
      "56                          obama makes fun of putin                       NaN\n",
      "57                       obama makes statement today                       NaN\n",
      "58                          obama makes fun of trump                       NaN\n",
      "59                        obama makes deal with iran                       NaN\n",
      "60                           obama makes racial slur                       NaN\n",
      "61                obama makes community college free                       NaN\n",
      "62                               obama makes me puke                       NaN\n",
      "63                 obama makes december 26 a holiday                       NaN\n",
      "64                   obama makes fun of donald trump                       NaN\n",
      "\n",
      "[65 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "#this function is used to get autosuggestions from a specified tld and language\n",
    "def get_suggestions(tld, lang, filename, subjects, predicates):\n",
    "\n",
    "    #initialize arrays\n",
    "    csvdata = []\n",
    "    bing_all = []\n",
    "    google_all = []\n",
    "    auto_bing = []\n",
    "    auto_google = []\n",
    "\n",
    "    #iterate through all subject+predicate combinations\n",
    "    for s in subjects:\n",
    "        for p in predicates:\n",
    "            query = s + \" \" + p + \" \"\n",
    "            auto_bing = collect_autosuggestions(\"bing\", tld, lang, query)\n",
    "            auto_google = collect_autosuggestions(\"google\", tld, lang, query)\n",
    "            bing_all.append(auto_bing)\n",
    "            google_all.append(auto_google)\n",
    "\n",
    "    #gather all autosuggestions from bing and save to array with index \"bing\"\n",
    "    bing_frames = []\n",
    "    for i in bing_all:\n",
    "        bing_frames.append(pd.DataFrame({\"bing\": i}))\n",
    "\n",
    "    bing_csv_data = pd.concat(bing_frames)\n",
    "\n",
    "    #repeat the process for google\n",
    "    google_frames = []\n",
    "    for i in google_all:\n",
    "        google_frames.append(pd.DataFrame({\"google\": i}))\n",
    "\n",
    "    #turn the array data into a dataframe\n",
    "    google_df = pd.concat([d for d in google_frames], ignore_index=True)\n",
    "    bing_df = pd.concat([d for d in bing_frames], ignore_index=True)\n",
    "    \n",
    "    #call join on the larger of the two dataframes to ensure no data is lost\n",
    "    if(len(bing_df)>len(google_df)):\n",
    "        result_df = bing_df.join(google_df)\n",
    "    else:\n",
    "        result_df = google_df.join(bing_df)\n",
    "        \n",
    "    #turn dataframe into a csv\n",
    "    result_df.to_csv(filename, encoding='utf-8')\n",
    "    return result_df\n",
    "\n",
    "\n",
    "#we combine one subject with one predicate per query from this list\n",
    "en_subjects = [\"USA\", \"America\", \"Barack Obama\", \"Obama\", \"The United States\"]\n",
    "en_predicates = [\"should\", \"is doing\", \"should be\", \"is\"]\n",
    "\n",
    "ru_subjects = [\"США\",\"Америка\",\"Барак Обама\", \"Обама\", \"Соединенные Штаты\"]\n",
    "ru_predicates = [\"должны\", \"делают\", \"должны быть\"] # 'is' doesn't have a russian equivalent\n",
    "\n",
    "es_subjects = [\"EE.UU.\", \"America\", \"Barack Obama\", \"Obama\", \"Estados Unidos\"]\n",
    "es_predicates = [\"debería\", \"está haciendo\", \"debería ser\", \"es\"]\n",
    "\n",
    "fr_subjects = [\"L'Amérique\",\"Barack Obama\", \"Obama\", \"Etats-Unis\"] #USA and United States have the same translation\n",
    "fr_predicates = [\"devrait\",\"fait\",\"devrait être\",\"est\"]\n",
    "\n",
    "#example run of the get_suggestions function:\n",
    "\n",
    "result_df = get_suggestions(\"ru\", \"ru\", \"ru_autosuggest.csv\", ru_subjects, ru_predicates)\n",
    "#result_df = get_suggestions(\"com\", \"en\", \"en_autosuggest.csv\", en_subjects, en_predicates)\n",
    "\n",
    "print result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "#open the files containing positive and negative terms, save to an array\n",
    "\n",
    "positive_terms = []\n",
    "f = open('Data/positive_terms.txt', \"r\")\n",
    "positive_terms = f.read().splitlines()\n",
    "f.close()\n",
    "\n",
    "negative_terms = []\n",
    "f = open('Data/negative_terms.txt', \"r\")\n",
    "negative_terms = f.read().splitlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>google</th>\n",
       "      <th>bing</th>\n",
       "      <th>bing_tokens</th>\n",
       "      <th>google_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>сша должны китаю</td>\n",
       "      <td>сша должны быть разрушен</td>\n",
       "      <td>[сша, должны, быть, разрушен]</td>\n",
       "      <td>[сша, должны, китаю]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>сша должны сами себе</td>\n",
       "      <td>сша должны быть разрушен</td>\n",
       "      <td>[сша, должны, быть, разрушен]</td>\n",
       "      <td>[сша, должны, сами, себе]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>сша должны россии</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[сша, должны, россии]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>сша должны быть разрушены</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[сша, должны, быть, разрушены]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>сша должны быть уничтожены</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[сша, должны, быть, уничтожены]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>сша должны китаю золото</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[сша, должны, китаю, золото]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>сша должны отдать нам украину</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[сша, должны, отдать, нам, украину]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>сша должны казахстану</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[сша, должны, казахстану]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>сша должны</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[сша, должны]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>сша должны сдохнуть</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[сша, должны, сдохнуть]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>в сша делают обрезание всем новорожденным</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[в, сша, делают, обрезание, всем, новорожденным]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>в сша делают обрезание</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[в, сша, делают, обрезание]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>как сша делают революции</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[как, сша, делают, революции]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>что делают сша в афганистане</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[что, делают, сша, в, афганистане]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>зачем в сша делают обрезание</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[зачем, в, сша, делают, обрезание]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>как в сша делают дорожную разметку</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[как, в, сша, делают, дорожную, разметку]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>что делают сша на украине</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[что, делают, сша, на, украине]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>что делают сша</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[что, делают, сша]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>usa makes world cup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[usa, make, world, cup]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>usa makes money on war</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[usa, make, money, war]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>сша должны быть разрушены</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[сша, должны, быть, разрушены]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>сша должны быть уничтожены</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[сша, должны, быть, уничтожены]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>великий вождь сша должны быть разрушены</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[великий, вождь, сша, должны, быть, разрушены]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>америка должна китаю</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[америка, должна, китаю]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>америка должна россии</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[америка, должна, россии]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>америка должна быть уничтожена</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[америка, должна, быть, уничтожена]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>америка должна всему миру</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[америка, должна, всему, миру]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>американцы должны умереть</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[американцы, должны, умереть]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>америка должна</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[америка, должна]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>америка должна сама себе</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[америка, должна, сама, себе]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>america makes namii</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[america, make, namii]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>america makes institute</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[america, make, institut]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>американцы делают обрезание</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[американцы, делают, обрезание]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>america makes us</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[america, make, us]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>america makes money from war</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[america, make, money, war]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>американцы делают попытку</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[американцы, делают, попытку]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>america makes youngstown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[america, make, youngstown]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>america makes fast quilts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[america, make, fast, quilt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>америка должна быть уничтожена</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[америка, должна, быть, уничтожена]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>сша должны быть уничтожены</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[сша, должны, быть, уничтожены]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>barack obama makes history</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[barack, obama, make, histori]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>barack obama makes fun of donald trump</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[barack, obama, make, fun, donald, trump]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>barack obama makes me sick</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[barack, obama, make, sick]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>barack obama makes baby stop crying</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[barack, obama, make, babi, stop, cri]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>barack obama makes a difference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[barack, obama, make, differ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>barack obama makes fun of himself</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[barack, obama, make, fun]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>barack obama makes fun of the bible</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[barack, obama, make, fun, bibl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>barack obama makes a joke</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[barack, obama, make, joke]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>barack obama makes fun of kim kardashian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[barack, obama, make, fun, kim, kardashian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>barack obama makes surprise visit to afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[barack, obama, make, surpris, visit, afghanis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>obama makes history</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[obama, make, histori]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>obama makes fun of putin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[obama, make, fun, putin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>obama makes statement today</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[obama, make, statement, today]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>obama makes fun of trump</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[obama, make, fun, trump]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>obama makes deal with iran</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[obama, make, deal, iran]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>obama makes racial slur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[obama, make, racial, slur]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>obama makes community college free</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[obama, make, commun, colleg, free]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>obama makes me puke</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[obama, make, puke]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>obama makes december 26 a holiday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[obama, make, decemb, 26, holiday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>obama makes fun of donald trump</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[obama, make, fun, donald, trump]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              google  \\\n",
       "0                                   сша должны китаю   \n",
       "1                               сша должны сами себе   \n",
       "2                                  сша должны россии   \n",
       "3                          сша должны быть разрушены   \n",
       "4                         сша должны быть уничтожены   \n",
       "5                            сша должны китаю золото   \n",
       "6                      сша должны отдать нам украину   \n",
       "7                              сша должны казахстану   \n",
       "8                                         сша должны   \n",
       "9                                сша должны сдохнуть   \n",
       "10         в сша делают обрезание всем новорожденным   \n",
       "11                            в сша делают обрезание   \n",
       "12                          как сша делают революции   \n",
       "13                      что делают сша в афганистане   \n",
       "14                      зачем в сша делают обрезание   \n",
       "15                как в сша делают дорожную разметку   \n",
       "16                         что делают сша на украине   \n",
       "17                                    что делают сша   \n",
       "18                               usa makes world cup   \n",
       "19                            usa makes money on war   \n",
       "20                         сша должны быть разрушены   \n",
       "21                        сша должны быть уничтожены   \n",
       "22           великий вождь сша должны быть разрушены   \n",
       "23                              америка должна китаю   \n",
       "24                             америка должна россии   \n",
       "25                    америка должна быть уничтожена   \n",
       "26                         америка должна всему миру   \n",
       "27                         американцы должны умереть   \n",
       "28                                    америка должна   \n",
       "29                          америка должна сама себе   \n",
       "..                                               ...   \n",
       "35                               america makes namii   \n",
       "36                           america makes institute   \n",
       "37                       американцы делают обрезание   \n",
       "38                                  america makes us   \n",
       "39                      america makes money from war   \n",
       "40                         американцы делают попытку   \n",
       "41                          america makes youngstown   \n",
       "42                         america makes fast quilts   \n",
       "43                    америка должна быть уничтожена   \n",
       "44                        сша должны быть уничтожены   \n",
       "45                        barack obama makes history   \n",
       "46            barack obama makes fun of donald trump   \n",
       "47                        barack obama makes me sick   \n",
       "48               barack obama makes baby stop crying   \n",
       "49                   barack obama makes a difference   \n",
       "50                 barack obama makes fun of himself   \n",
       "51               barack obama makes fun of the bible   \n",
       "52                         barack obama makes a joke   \n",
       "53          barack obama makes fun of kim kardashian   \n",
       "54  barack obama makes surprise visit to afghanistan   \n",
       "55                               obama makes history   \n",
       "56                          obama makes fun of putin   \n",
       "57                       obama makes statement today   \n",
       "58                          obama makes fun of trump   \n",
       "59                        obama makes deal with iran   \n",
       "60                           obama makes racial slur   \n",
       "61                obama makes community college free   \n",
       "62                               obama makes me puke   \n",
       "63                 obama makes december 26 a holiday   \n",
       "64                   obama makes fun of donald trump   \n",
       "\n",
       "                        bing                    bing_tokens  \\\n",
       "0   сша должны быть разрушен  [сша, должны, быть, разрушен]   \n",
       "1   сша должны быть разрушен  [сша, должны, быть, разрушен]   \n",
       "2                        NaN                             []   \n",
       "3                        NaN                             []   \n",
       "4                        NaN                             []   \n",
       "5                        NaN                             []   \n",
       "6                        NaN                             []   \n",
       "7                        NaN                             []   \n",
       "8                        NaN                             []   \n",
       "9                        NaN                             []   \n",
       "10                       NaN                             []   \n",
       "11                       NaN                             []   \n",
       "12                       NaN                             []   \n",
       "13                       NaN                             []   \n",
       "14                       NaN                             []   \n",
       "15                       NaN                             []   \n",
       "16                       NaN                             []   \n",
       "17                       NaN                             []   \n",
       "18                       NaN                             []   \n",
       "19                       NaN                             []   \n",
       "20                       NaN                             []   \n",
       "21                       NaN                             []   \n",
       "22                       NaN                             []   \n",
       "23                       NaN                             []   \n",
       "24                       NaN                             []   \n",
       "25                       NaN                             []   \n",
       "26                       NaN                             []   \n",
       "27                       NaN                             []   \n",
       "28                       NaN                             []   \n",
       "29                       NaN                             []   \n",
       "..                       ...                            ...   \n",
       "35                       NaN                             []   \n",
       "36                       NaN                             []   \n",
       "37                       NaN                             []   \n",
       "38                       NaN                             []   \n",
       "39                       NaN                             []   \n",
       "40                       NaN                             []   \n",
       "41                       NaN                             []   \n",
       "42                       NaN                             []   \n",
       "43                       NaN                             []   \n",
       "44                       NaN                             []   \n",
       "45                       NaN                             []   \n",
       "46                       NaN                             []   \n",
       "47                       NaN                             []   \n",
       "48                       NaN                             []   \n",
       "49                       NaN                             []   \n",
       "50                       NaN                             []   \n",
       "51                       NaN                             []   \n",
       "52                       NaN                             []   \n",
       "53                       NaN                             []   \n",
       "54                       NaN                             []   \n",
       "55                       NaN                             []   \n",
       "56                       NaN                             []   \n",
       "57                       NaN                             []   \n",
       "58                       NaN                             []   \n",
       "59                       NaN                             []   \n",
       "60                       NaN                             []   \n",
       "61                       NaN                             []   \n",
       "62                       NaN                             []   \n",
       "63                       NaN                             []   \n",
       "64                       NaN                             []   \n",
       "\n",
       "                                        google_tokens  \n",
       "0                                [сша, должны, китаю]  \n",
       "1                           [сша, должны, сами, себе]  \n",
       "2                               [сша, должны, россии]  \n",
       "3                      [сша, должны, быть, разрушены]  \n",
       "4                     [сша, должны, быть, уничтожены]  \n",
       "5                        [сша, должны, китаю, золото]  \n",
       "6                 [сша, должны, отдать, нам, украину]  \n",
       "7                           [сша, должны, казахстану]  \n",
       "8                                       [сша, должны]  \n",
       "9                             [сша, должны, сдохнуть]  \n",
       "10   [в, сша, делают, обрезание, всем, новорожденным]  \n",
       "11                        [в, сша, делают, обрезание]  \n",
       "12                      [как, сша, делают, революции]  \n",
       "13                 [что, делают, сша, в, афганистане]  \n",
       "14                 [зачем, в, сша, делают, обрезание]  \n",
       "15          [как, в, сша, делают, дорожную, разметку]  \n",
       "16                    [что, делают, сша, на, украине]  \n",
       "17                                 [что, делают, сша]  \n",
       "18                            [usa, make, world, cup]  \n",
       "19                            [usa, make, money, war]  \n",
       "20                     [сша, должны, быть, разрушены]  \n",
       "21                    [сша, должны, быть, уничтожены]  \n",
       "22     [великий, вождь, сша, должны, быть, разрушены]  \n",
       "23                           [америка, должна, китаю]  \n",
       "24                          [америка, должна, россии]  \n",
       "25                [америка, должна, быть, уничтожена]  \n",
       "26                     [америка, должна, всему, миру]  \n",
       "27                      [американцы, должны, умереть]  \n",
       "28                                  [америка, должна]  \n",
       "29                      [америка, должна, сама, себе]  \n",
       "..                                                ...  \n",
       "35                             [america, make, namii]  \n",
       "36                          [america, make, institut]  \n",
       "37                    [американцы, делают, обрезание]  \n",
       "38                                [america, make, us]  \n",
       "39                        [america, make, money, war]  \n",
       "40                      [американцы, делают, попытку]  \n",
       "41                        [america, make, youngstown]  \n",
       "42                       [america, make, fast, quilt]  \n",
       "43                [америка, должна, быть, уничтожена]  \n",
       "44                    [сша, должны, быть, уничтожены]  \n",
       "45                     [barack, obama, make, histori]  \n",
       "46          [barack, obama, make, fun, donald, trump]  \n",
       "47                        [barack, obama, make, sick]  \n",
       "48             [barack, obama, make, babi, stop, cri]  \n",
       "49                      [barack, obama, make, differ]  \n",
       "50                         [barack, obama, make, fun]  \n",
       "51                   [barack, obama, make, fun, bibl]  \n",
       "52                        [barack, obama, make, joke]  \n",
       "53        [barack, obama, make, fun, kim, kardashian]  \n",
       "54  [barack, obama, make, surpris, visit, afghanis...  \n",
       "55                             [obama, make, histori]  \n",
       "56                          [obama, make, fun, putin]  \n",
       "57                    [obama, make, statement, today]  \n",
       "58                          [obama, make, fun, trump]  \n",
       "59                          [obama, make, deal, iran]  \n",
       "60                        [obama, make, racial, slur]  \n",
       "61                [obama, make, commun, colleg, free]  \n",
       "62                                [obama, make, puke]  \n",
       "63                 [obama, make, decemb, 26, holiday]  \n",
       "64                  [obama, make, fun, donald, trump]  \n",
       "\n",
       "[65 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string \n",
    "import numpy as np\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "# Create a tokenizer from nltk which will create tokens based on the whitespace in between words\n",
    "tokenizer = WhitespaceTokenizer()\n",
    "\n",
    "#import tools to help with the sentiment analysis\n",
    "from nltk.corpus import stopwords\n",
    "stopword_list = stopwords.words('english')\n",
    "porter = nltk.PorterStemmer()\n",
    "\n",
    "#remove any punctuation from the autosuggestions\n",
    "def remove_punctuation(text):\n",
    "    # Grab the list of standard punctuation symbols that are provided in the string library\n",
    "    punctuations = string.punctuation # includes following characters: !\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\n",
    "\n",
    "    # But don't strip out apostrophes, as we want to preserve possessives and contractions, an alternative would be to expand contractions\n",
    "    excluded_punctuations = [\"'\"]\n",
    "    for p in punctuations:\n",
    "        if p not in excluded_punctuations:\n",
    "            # replace each punctuation symbol by a space\n",
    "            text = text.replace(p, \" \") \n",
    "\n",
    "    return text\n",
    "\n",
    "#turn autosuggestion text into token array\n",
    "def normalize_review_text(text):\n",
    "    if pd.isnull(text):\n",
    "        return [\"\"]\n",
    "    text = text.lower()\n",
    "    text = remove_punctuation(text)\n",
    "    text = \" \".join(text.split())\n",
    "    text_tokens = tokenizer.tokenize(text)\n",
    "    text_tokens = [porter.stem(w) for w in text_tokens if w not in stopword_list]\n",
    "    return text_tokens\n",
    "\n",
    "# Apply the function above to the text column\n",
    "def normalize_dataframe(result_df):\n",
    "    result_df[\"bing_tokens\"] = result_df[\"bing\"].apply(normalize_review_text)\n",
    "    result_df[\"google_tokens\"] = result_df[\"google\"].apply(normalize_review_text)\n",
    "    return result_df\n",
    "\n",
    "normalize_dataframe(result_df)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_positivity(text):\n",
    "    num_tokens = len(text)\n",
    "    num_positive_tokens = 0\n",
    "    for t in text:\n",
    "        if t in positive_terms:\n",
    "            num_positive_tokens = num_positive_tokens + 1\n",
    "    # The positivity score is the fraction of tokens that were found in the positive dictionary\n",
    "    return float(num_positive_tokens) / float(num_tokens)\n",
    "\n",
    "\n",
    "def calculate_negativity(text):\n",
    "    num_tokens = len(text)\n",
    "    num_negative_tokens = 0\n",
    "    for t in text:\n",
    "        if t in negative_terms:\n",
    "            num_negative_tokens = num_negative_tokens + 1\n",
    "    # The negativity score is the fraction of tokens that were found in the negative dictionary\n",
    "    return float(num_negative_tokens) / float(num_tokens)\n",
    "\n",
    "#add sentiment data into the dataframe and csv\n",
    "def get_sentiment(result_df, filename):\n",
    "    result_df[\"bing_positivity_score\"] = result_df[\"bing_tokens\"].apply(calculate_positivity)\n",
    "    result_df[\"google_positivity_score\"] = result_df[\"google_tokens\"].apply(calculate_positivity)\n",
    "    result_df[\"bing_negativity_score\"] = result_df[\"bing_tokens\"].apply(calculate_negativity)\n",
    "    result_df[\"google_negativity_score\"] = result_df[\"google_tokens\"].apply(calculate_negativity)\n",
    "    result_df = result_df[[\"bing\",\"bing_tokens\",\"bing_positivity_score\",\"bing_negativity_score\",\"google\",\"google_tokens\",\"google_positivity_score\",\"google_negativity_score\"]]\n",
    "    result_df.to_csv(filename, encoding='utf-8')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print the avg. positivity/negativity sentiment of bing and google autosuggestions\n",
    "def print_results(result_df):\n",
    "    #bing scores\n",
    "    total_score = 0\n",
    "    for i in result_df[\"bing_positivity_score\"]:\n",
    "        total_score += i\n",
    "\n",
    "    bing_pos_avg = total_score/result_df[\"bing\"].count()\n",
    "    print \"Bing positivity avg:\",bing_pos_avg\n",
    "\n",
    "    total_score = 0\n",
    "    for i in result_df[\"bing_negativity_score\"]:\n",
    "        total_score += i\n",
    "\n",
    "    bing_neg_avg = total_score/result_df[\"bing\"].count()\n",
    "    print \"Bing negativity avg:\",bing_neg_avg\n",
    "\n",
    "    #google scores\n",
    "    total_score = 0\n",
    "    for i in result_df[\"google_positivity_score\"]:\n",
    "        total_score += i\n",
    "\n",
    "    google_pos_avg = total_score/result_df[\"google\"].count()\n",
    "    print \"Google positivity avg:\",google_pos_avg\n",
    "\n",
    "    total_score = 0\n",
    "    for i in result_df[\"google_negativity_score\"]:\n",
    "        total_score += i\n",
    "\n",
    "    google_neg_avg = total_score/result_df[\"google\"].count()\n",
    "    print \"Google negativity avg:\",google_neg_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "#return 25 most common words from the autosuggestions, excluding subjects/predicates used earlier\n",
    "def get_most_common_en(result_df):\n",
    "    bing_tokens_total = []\n",
    "    for t in result_df[\"bing_tokens\"]:\n",
    "        bing_tokens_total += t\n",
    "\n",
    "    bing_tokens_total = [x for x in bing_tokens_total if x != \"obama\" and x !=\"america\" and x !=\"usa\" \\\n",
    "                        and x != \"barack\" and x !=\"unit\" and x != \"state\" and x!=\"\"]    \n",
    "\n",
    "    bing_frequency_distribution = FreqDist(bing_tokens_total)\n",
    "    bing_common = bing_frequency_distribution.most_common(25)\n",
    "\n",
    "    print \"Bing Tokens FreqDist: \", bing_common\n",
    "\n",
    "    google_tokens_total = []\n",
    "    for t in result_df[\"google_tokens\"]:\n",
    "        google_tokens_total += t\n",
    "\n",
    "    google_tokens_total = [x for x in google_tokens_total if x != \"obama\" and x !=\"america\" and x !=\"usa\" \\\n",
    "                        and x != \"barack\" and x !=\"unit\" and x != \"state\" and x!=\"\"]    \n",
    "\n",
    "    google_frequency_distribution = FreqDist(google_tokens_total)\n",
    "    google_common = google_frequency_distribution.most_common(25)\n",
    "\n",
    "    print \"\\nGoogle Tokens FreqDist: \", google_common\n",
    "    return [bing_common, google_common]\n",
    "\n",
    "#use this for non-english languages since stemming will not occur; just compare to subject array\n",
    "def get_most_common(result_df, subjects):\n",
    "    bing_tokens_total = []\n",
    "    for t in result_df[\"bing_tokens\"]:\n",
    "        bing_tokens_total += t\n",
    "\n",
    "    bing_tokens_total = [x for x in bing_tokens_total if x not in subjects]    \n",
    "\n",
    "    bing_frequency_distribution = FreqDist(bing_tokens_total)\n",
    "    bing_common = bing_frequency_distribution.most_common(25)\n",
    "\n",
    "    print \"Bing Tokens FreqDist: \", bing_common\n",
    "\n",
    "    google_tokens_total = []\n",
    "    for t in result_df[\"google_tokens\"]:\n",
    "        google_tokens_total += t\n",
    "\n",
    "    google_tokens_total = [x for x in google_tokens_total if x not in subjects]    \n",
    "\n",
    "    google_frequency_distribution = FreqDist(google_tokens_total)\n",
    "    google_common = google_frequency_distribution.most_common(25)\n",
    "\n",
    "    print \"\\nGoogle Tokens FreqDist: \", google_common\n",
    "    return [bing_common, google_common]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Russia\n",
      "Bing positivity avg: 0.0\n",
      "Bing negativity avg: 0.0\n",
      "Google positivity avg: 0.0323076923077\n",
      "Google negativity avg: 0.00769230769231\n",
      "Bing Tokens FreqDist:  [('', 63), (u'\\u0441\\u0448\\u0430', 2), (u'\\u0440\\u0430\\u0437\\u0440\\u0443\\u0448\\u0435\\u043d', 2), (u'\\u0431\\u044b\\u0442\\u044c', 2), (u'\\u0434\\u043e\\u043b\\u0436\\u043d\\u044b', 2)]\n",
      "\n",
      "Google Tokens FreqDist:  [(u'make', 30), (u'\\u0441\\u0448\\u0430', 22), (u'obama', 20), (u'\\u0434\\u043e\\u043b\\u0436\\u043d\\u044b', 15), (u'barack', 10), (u'\\u0434\\u043e\\u043b\\u0436\\u043d\\u0430', 10), (u'\\u0430\\u043c\\u0435\\u0440\\u0438\\u043a\\u0430', 10), (u'\\u0434\\u0435\\u043b\\u0430\\u044e\\u0442', 10), (u'\\u0431\\u044b\\u0442\\u044c', 8), (u'america', 8), (u'fun', 7), (u'\\u0432', 5), (u'\\u043e\\u0431\\u0440\\u0435\\u0437\\u0430\\u043d\\u0438\\u0435', 4), (u'\\u043a\\u0438\\u0442\\u0430\\u044e', 4), (u'\\u0447\\u0442\\u043e', 3), (u'\\u0443\\u043d\\u0438\\u0447\\u0442\\u043e\\u0436\\u0435\\u043d\\u044b', 3), (u'\\u0440\\u0430\\u0437\\u0440\\u0443\\u0448\\u0435\\u043d\\u044b', 3), (u'trump', 3), (u'\\u0430\\u043c\\u0435\\u0440\\u0438\\u043a\\u0430\\u043d\\u0446\\u044b', 3), (u'money', 2), (u'\\u0443\\u043c\\u0435\\u0440\\u0435\\u0442\\u044c', 2), (u'\\u0441\\u0435\\u0431\\u0435', 2), (u'donald', 2), (u'\\u0443\\u043d\\u0438\\u0447\\u0442\\u043e\\u0436\\u0435\\u043d\\u0430', 2), (u'\\u0440\\u043e\\u0441\\u0441\\u0438\\u0438', 2)]\n",
      "\n",
      "USA\n",
      "Bing positivity avg: 0.0222027972028\n",
      "Bing negativity avg: 0.0342074592075\n",
      "Google positivity avg: 0.0408752327747\n",
      "Google negativity avg: 0.0294227188082\n",
      "Bing Tokens FreqDist:  [(u'go', 37), (u'presid', 17), (u'countri', 13), (u'republ', 12), (u'democraci', 8), (u'gun', 6), (u'number', 6), (u'war', 6), (u'take', 5), (u'corpor', 5), (u'ban', 5), (u'constitut', 5), (u'away', 5), (u'refuge', 5), (u'great', 5), (u'system', 5), (u'stay', 5), (u'hell', 4), (u'stop', 4), (u'44th', 4), (u'job', 4), (u'isi', 4), (u'nuke', 4), (u'metric', 4), (u'good', 4)]\n",
      "\n",
      "Google Tokens FreqDist:  [(u'us', 14), (u'isi', 9), (u'presid', 6), (u'isolationist', 5), (u'stop', 5), (u'ebola', 5), (u'democraci', 5), (u'impeach', 4), (u'invad', 4), (u'destroy', 4), (u'syria', 4), (u'okinawa', 3), (u'busi', 3), (u'world', 3), (u'anyth', 3), (u'dougi', 3), (u'best', 3), (u'enough', 3), (u'great', 3), (u'nuke', 3), (u'interven', 3), (u'asham', 3), (u'oligarchi', 3), (u'comedian', 3), (u'exampl', 3)]\n",
      "\n",
      "UK\n",
      "Bing positivity avg: 0.0222027972028\n",
      "Bing negativity avg: 0.0342074592075\n",
      "Google positivity avg: 0.0408752327747\n",
      "Google negativity avg: 0.0294227188082\n",
      "Bing Tokens FreqDist:  [(u'go', 37), (u'presid', 17), (u'countri', 13), (u'republ', 12), (u'democraci', 8), (u'gun', 6), (u'number', 6), (u'war', 6), (u'take', 5), (u'corpor', 5), (u'ban', 5), (u'constitut', 5), (u'away', 5), (u'refuge', 5), (u'great', 5), (u'system', 5), (u'stay', 5), (u'hell', 4), (u'stop', 4), (u'44th', 4), (u'job', 4), (u'isi', 4), (u'nuke', 4), (u'metric', 4), (u'good', 4)]\n",
      "\n",
      "Google Tokens FreqDist:  [(u'us', 13), (u'isi', 9), (u'presid', 6), (u'isolationist', 5), (u'stop', 5), (u'ebola', 5), (u'impeach', 4), (u'invad', 4), (u'destroy', 4), (u'syria', 4), (u'okinawa', 3), (u'busi', 3), (u'world', 3), (u'anyth', 3), (u'dougi', 3), (u'best', 3), (u'enough', 3), (u'great', 3), (u'nuke', 3), (u'system', 3), (u'interven', 3), (u'asham', 3), (u'comedian', 3), (u'democraci', 3), (u'exampl', 3)]\n",
      "\n",
      "Mexico\n",
      "Bing positivity avg: 0.00909090909091\n",
      "Bing negativity avg: 0.0\n",
      "Google positivity avg: 0.0025641025641\n",
      "Google negativity avg: 0.00192307692308\n",
      "Bing Tokens FreqDist:  [(u'es', 36), ('', 21), (u'obama', 19), (u'unido', 12), (u'estado', 12), (u'am\\xe9rica', 12), (u'barack', 11), (u'un', 11), (u'pa\\xed', 6), (u'en', 5), (u'de', 4), (u'el', 3), (u'continent', 3), (u'laden', 3), (u'capitalista', 3), (u'bin', 3), (u'que', 3), (u'm\\xe9xico', 3), (u'receptor', 2), (u'mejor', 2), (u'alien', 2), (u'poco', 2), (u'grand', 2), (u'por', 2), (u'osama', 2)]\n",
      "\n",
      "Google Tokens FreqDist:  [(u'es', 41), (u'obama', 30), (u'estado', 23), (u'unido', 21), (u'america', 14), (u'un', 12), (u'debe', 11), (u'haciendo', 11), (u'barack', 10), (u'la', 5), (u'de', 5), (u'el', 5), (u'pai', 5), (u'en', 4), (u'continent', 3), (u'lo', 3), (u'deberia', 3), (u'ser', 3), (u'ejercicio', 3), (u'para', 3), (u'bin', 2), (u'capitalista', 2), (u'siria', 2), (u'ice', 2), (u'intervenir', 2)]\n",
      "\n",
      "Canada (FR)\n",
      "Bing positivity avg: 0.0309523809524\n",
      "Bing negativity avg: 0.0261904761905\n",
      "Google positivity avg: 0.00639269406393\n",
      "Google negativity avg: 0.0\n",
      "Bing Tokens FreqDist:  [('', 38), (u'obama', 34), (u'barack', 15), (u'et', 7), (u'father', 5), (u'tube', 2), (u'religion', 2), (u'state', 2), (u'easter', 2), (u'leader', 2), (u'test', 2), (u'faith', 2), (u'east', 2), (u'castro', 2), (u'struggl', 2), (u'presid', 2), (u'tribe', 1), (u'fatherhood', 1), (u'schedul', 1), (u'sign', 1), (u'il', 1), (u'fairey', 1), (u'fitbit', 1), (u'divorc', 1), (u'st', 1)]\n",
      "\n",
      "Google Tokens FreqDist:  [(u'est', 41), (u'obama', 38), (u'fait', 33), (u'barack', 18), (u'uni', 15), (u\"l'am\\xe9riqu\", 15), (u'un', 14), (u'etat', 14), (u'le', 10), (u'de', 9), (u'il', 8), (u'pay', 7), (u'la', 6), (u'ou', 6), (u'ell', 4), (u'du', 4), (u'rever', 4), (u'pourquoi', 4), (u'show', 3), (u'pr\\xe9sident', 3), (u'ouest', 3), (u'parti', 3), (u\"l'ameriqu\", 3), (u'se', 3), (u'skate', 2)]\n",
      "\n",
      "Canada (EN)\n",
      "Bing positivity avg: 0.0225988700565\n",
      "Bing negativity avg: 0.0810734463277\n",
      "Google positivity avg: 0.0408752327747\n",
      "Google negativity avg: 0.0294227188082\n",
      "Bing Tokens FreqDist:  [(u'go', 5), (u'canada', 4), (u'countri', 4), (u'greatest', 4), (u'corpor', 2), (u'gog', 2), (u'republ', 2), (u'leader', 2), (u'power', 2), (u'free', 2), (u'invad', 2), (u'presid', 2), (u'scare', 2), (u'evil', 2), (u'stay', 2), (u'pant', 1), (u'german', 1), (u'move', 1), (u'bring', 1), (u'still', 1), (u'shiit', 1), (u'thanksgiv', 1), (u'polici', 1), (u'better', 1), (u\"world'\", 1)]\n",
      "\n",
      "Google Tokens FreqDist:  [(u'us', 13), (u'isi', 9), (u'presid', 6), (u'isolationist', 5), (u'stop', 5), (u'ebola', 5), (u'impeach', 4), (u'invad', 4), (u'destroy', 4), (u'syria', 4), (u'okinawa', 3), (u'busi', 3), (u'world', 3), (u'anyth', 3), (u'dougi', 3), (u'best', 3), (u'enough', 3), (u'great', 3), (u'nuke', 3), (u'system', 3), (u'interven', 3), (u'asham', 3), (u'comedian', 3), (u'democraci', 3), (u'exampl', 3)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steven\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:34: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "C:\\Users\\Steven\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:45: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    }
   ],
   "source": [
    "print \"\\nRussia\"\n",
    "result_df = get_suggestions(\"ru\", \"ru\", \"ru_autosuggestions.csv\", ru_subjects, ru_predicates)\n",
    "normalize_dataframe(result_df)\n",
    "get_sentiment(result_df, \"ru_autosuggestions.csv\")\n",
    "print_results(result_df)\n",
    "#print result_df\n",
    "ru_common = get_most_common(result_df, ru_subjects)\n",
    "\n",
    "#now get various \"most common\" arrays from different tlds and languages and see which tokens appear the most\n",
    "print \"\\nUSA\"\n",
    "usa_df = get_suggestions(\"com\", \"en\", \"usa_autosuggestions.csv\", en_subjects, en_predicates)\n",
    "normalize_dataframe(usa_df)\n",
    "get_sentiment(usa_df, \"usa_autosuggestions.csv\")\n",
    "print_results(usa_df)\n",
    "#print usa_df\n",
    "usa_common = get_most_common_en(usa_df)\n",
    "\n",
    "print \"\\nUK\"\n",
    "uk_df = get_suggestions(\"co.uk\", \"en\", \"uk_autosuggestions.csv\", en_subjects, en_predicates)\n",
    "normalize_dataframe(uk_df)\n",
    "get_sentiment(uk_df, \"uk_autosuggestions.csv\")\n",
    "print_results(uk_df)\n",
    "#print uk_df\n",
    "uk_common = get_most_common_en(uk_df)\n",
    "\n",
    "print \"\\nMexico\"\n",
    "mx_df = get_suggestions(\"mx\", \"es\", \"mx_autosuggestions.csv\", es_subjects, es_predicates)\n",
    "normalize_dataframe(mx_df)\n",
    "get_sentiment(mx_df, \"mx_autosuggestions.csv\")\n",
    "print_results(mx_df)\n",
    "#print mx_df\n",
    "mx_common = get_most_common(mx_df, es_subjects)\n",
    "\n",
    "print \"\\nCanada (FR)\"\n",
    "ca_df = get_suggestions(\"ca\", \"fr\", \"ca_autosuggestions.csv\", fr_subjects, fr_predicates)\n",
    "normalize_dataframe(ca_df)\n",
    "get_sentiment(ca_df, \"ca_autosuggestions.csv\")\n",
    "print_results(ca_df)\n",
    "#print ca_df\n",
    "ca_common = get_most_common(ca_df, fr_subjects)\n",
    "\n",
    "print \"\\nCanada (EN)\"\n",
    "ca_en_df = get_suggestions(\"ca\", \"en\", \"ca_en_autosuggestions.csv\", en_subjects, en_predicates)\n",
    "normalize_dataframe(ca_en_df)\n",
    "get_sentiment(ca_en_df, \"ca_en_autosuggestions.csv\")\n",
    "print_results(ca_en_df)\n",
    "#print ca_en_df\n",
    "ca_en_common = get_most_common_en(ca_en_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#used to generate charts\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#get font support for non-English characters\n",
    "matplotlib.rcdefaults()\n",
    "matplotlib.rcParams['font.family'] = 'fantasy'\n",
    "matplotlib.rcParams['font.fantasy'] = 'Times New Roman','Arial','Tahoma','Calibri'\n",
    "\n",
    "#adapted from code found here: http://cs.smith.edu/dftwiki/index.php/MatPlotLib_Tutorial_1#Adding_String_Labels_for_X_Values\n",
    "def visualize(common, clr):\n",
    "    #omit invalid terms\n",
    "    bing_u = [(x,i) for (x,i) in common[0] if isinstance(x, unicode)]\n",
    "    google_u = [(x,i) for (x,i) in common[1] if isinstance(x, unicode)]\n",
    "    \n",
    "    #plot data\n",
    "    N = len(bing_u)\n",
    "    x = np.arange(1, N+1)\n",
    "    y = [ num for (s, num) in bing_u ]\n",
    "    labels = [ s for (s, num) in bing_u ]\n",
    "    width = 1\n",
    "    bar1 = plt.bar( x, y, width, color=clr )\n",
    "    plt.ylabel('Bing Term Frequency')\n",
    "    plt.xticks(x + width/2.0, labels )\n",
    "    locs, labels = plt.xticks()\n",
    "    plt.setp(labels, rotation=90)\n",
    "    plt.show()\n",
    "    \n",
    "    N = len(google_u)\n",
    "    x = np.arange(1, N+1)\n",
    "    y = [ num for (s, num) in google_u ]\n",
    "    labels = [ s for (s, num) in google_u ]\n",
    "    width = 1\n",
    "    bar1 = plt.bar( x, y, width, color=clr )\n",
    "    plt.ylabel('Google Term Frequency')\n",
    "    plt.xticks(x + width/2.0, labels )\n",
    "    locs, labels = plt.xticks()\n",
    "    plt.setp(labels, rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "#plot results\n",
    "all_results = [(ru_common,\"#ff0000\"), (usa_common,\"#0000ff\"), (uk_common,\"#33ff99\"), (mx_common,\"#ffff00\"), (ca_common,\"#dd8855\"), (ca_en_common, \"#aabbcc\")]\n",
    "for (i,c) in all_results:\n",
    "    visualize(i,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
